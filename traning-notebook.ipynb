{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a id=\"title_ID\"></a>\n","<font color='#425066'><center><h1>Text-to-code Generation (NLP Assignment 2)</h1></center></font>\n","\n","\n","<a id=\"section1\"><font color='#FF6F00'><h2>Introduction</h2></font></a>\n","\n","\n","Text-to-code generation is a task where we can generate code based on the natural language description. It can further be used to build an AI-powered coding assistant. Developers simply type the natural language description or the function signature to specify their intents, and the AI coding assistant can generate or complete the target function for them. This helps to accelerate implementation and also reduce their reliance on external resources.\n","\n","<br>\n","\n","<br>\n","\n","CodeT5 by Salesforce is the first code-aware, encoder-decoder-based pre-trained programming language model, which enables a wide range of code intelligence applications including code understanding and generation tasks.\n","\n","\n","In this notebook we will finetune CodeT5 on MBPP - Mostly Basic Python Problems by Google Research to generate code based on problem description. MBPP is a benchmark that consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases.\n","\n","<b>The notebook demonstrates how to finetune CodeT5 on MBPP Dataset w/ TensorFlow.</b>\n","\n","Let's start by importing required libraries to the environment: \n","\n","- [*TensorFlow*](https://www.tensorflow.org/) an end-to-end open source platform for machine learning.\n","- [*transformers*](https://huggingface.co/docs/transformers/index) provides APIs to easily download and train state-of-the-art pretrained models\n","- [*datasets*](https://huggingface.co/docs/datasets/index) a library for easily accessing and sharing datasets."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:59:59.423609Z","iopub.status.busy":"2024-05-13T19:59:59.422868Z","iopub.status.idle":"2024-05-13T20:00:16.806180Z","shell.execute_reply":"2024-05-13T20:00:16.805173Z","shell.execute_reply.started":"2024-05-13T19:59:59.423566Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","TF version 2.6.2\n","Num GPUs Available:  1\n"]}],"source":["import os\n","import time\n","import math\n","import random\n","import datetime\n","from pathlib import Path\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # reduce the amount of console output from TF\n","import tensorflow as tf\n","\n","from transformers import *\n","!pip install -q datasets \n","from datasets import load_dataset\n","\n","logging.set_verbosity_warning()\n","logging.set_verbosity_error()\n","\n","import logging\n","\n","print('TF version',tf.__version__)\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:00:16.808530Z","iopub.status.busy":"2024-05-13T20:00:16.808270Z","iopub.status.idle":"2024-05-13T20:00:16.819815Z","shell.execute_reply":"2024-05-13T20:00:16.819049Z","shell.execute_reply.started":"2024-05-13T20:00:16.808501Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Tensorflow: setting up strategy\n"," XLA Enabled\n"," One Device Strategy [GPU] Enabled\n"]}],"source":["def setup_strategy(xla, fp16, no_cuda):\n","    print(\" Tensorflow: setting up strategy\")\n","    \n","    \n","    if xla:\n","        print(\" XLA Enabled\")\n","        tf.config.optimizer.set_jit(True)\n","    \n","    # setup mixed precision training\n","    if fp16:\n","        # Set to float16 at first\n","        print(\" Mixed Precision Training Enabled\")\n","        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n","        tf.keras.mixed_precision.experimental.set_policy(policy)\n","    \n","    # setup distribution strategy\n","    gpus = tf.config.list_physical_devices(\"GPU\")\n","    if no_cuda:\n","        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n","    else:\n","        if len(gpus) == 0:\n","            print(\" One Device Strategy [CPU] Enabled\")\n","            strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n","        elif len(gpus) == 1:\n","            print(\" One Device Strategy [GPU] Enabled\")\n","            strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n","        elif len(gpus) > 1:\n","            print(\" Mirrored Strategy Enabled\")\n","            \n","            strategy = tf.distribute.MirroredStrategy()\n","        else:\n","            strategy = tf.distribute.get_strategy()\n","\n","    return strategy\n","\n","def n_replicas(strategy):\n","    # return number of devices\n","    return strategy.num_replicas_in_sync\n","\n","\n","strategy = setup_strategy(xla=True, fp16=False, no_cuda=False)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:00:16.821641Z","iopub.status.busy":"2024-05-13T20:00:16.821379Z","iopub.status.idle":"2024-05-13T20:00:16.842584Z","shell.execute_reply":"2024-05-13T20:00:16.841839Z","shell.execute_reply.started":"2024-05-13T20:00:16.821606Z"},"trusted":true},"outputs":[],"source":["def download_dataset(cache_dir):\n","    \n","    _url = \"https://raw.githubusercontent.com/google-research/google-research/master/mbpp/mbpp.jsonl\" \n","    dataset_path = tf.keras.utils.get_file(\"mbpp.jsonl\", origin=_url, cache_dir=cache_dir, cache_subdir=cache_dir)\n","    return dataset_path \n","\n","def convert_examples_to_features(examples, tokenizer, args):\n","    \n","    texts = examples['text']\n","    codes = examples['code']\n","    # tests = [\" \".join(test) for test in examples['test_list']] # convert list of test cases to single string\n","    \n","    # encode texts by prepending the task for input sequence\n","    inputs = [args.prefix + text for text in texts]\n","    model_inputs = tokenizer(inputs, max_length=args.max_input_length, padding=\"max_length\", truncation=True)\n","    \n","    \n","    # encode texts by prepending the task for input sequence\n","    labels = tokenizer(codes, max_length=args.max_target_length, padding=\"max_length\", truncation=True).input_ids\n","    \n","    # we need to replace the index of the padding tokens by -100\n","    # such that they are not taken into account by the CrossEntropyLoss\n","    labels_with_ignore_index = []\n","    for labels_example in labels:\n","        labels_example = [label if label != 0 else -100 for label in labels_example]\n","        labels_with_ignore_index.append(labels_example)\n","    model_inputs[\"labels\"] = labels_with_ignore_index\n","    \n","    # return features\n","    return model_inputs\n","\n","\n","def get_train_tfdataset(train_dataset, num_train_examples, args):\n","    # select feature columns\n","    columns = ['input_ids', 'attention_mask', 'labels'] \n","    # set to tensorflow format\n","    train_dataset.set_format(type='tensorflow', columns=columns) \n","    \n","    # specify return types\n","    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, 'labels':tf.int32} \n","    # specify return shapes\n","    return_shapes = {'input_ids': tf.TensorShape([None]),'attention_mask': tf.TensorShape([None]), 'labels': tf.TensorShape([None])} \n","    # initialize dataset \n","    tf_dataset = tf.data.Dataset.from_generator(lambda : train_dataset, return_types, return_shapes) \n","    \n","    # turn off auto-sharding\n","    options = tf.data.Options()\n","    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","    tf_dataset = tf_dataset.with_options(options)\n","    \n","    # repeat, shuffle, batch, prefetch\n","    ds = (\n","        tf_dataset.repeat()\n","        .shuffle(num_train_examples, seed=args.seed)\n","        .batch(args.train_batch_size)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","    \n","    # distribute dataset to devices\n","    return strategy.experimental_distribute_dataset(ds)\n","\n","def get_validation_tfdataset(eval_dataset, num_validation_examples, args):\n","    # select feature columns\n","    columns = ['input_ids', 'attention_mask', 'labels'] \n","    # set to tensorflow format\n","    eval_dataset.set_format(type='tensorflow', columns=columns) \n","    \n","    # specify return types\n","    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, 'labels':tf.int32} \n","    # specify return shapes\n","    return_shapes = {'input_ids': tf.TensorShape([None]),'attention_mask': tf.TensorShape([None]), 'labels': tf.TensorShape([None])} \n","    # initialize dataset \n","    tf_dataset = tf.data.Dataset.from_generator(lambda : eval_dataset, return_types, return_shapes) \n","    \n","    # turn off auto-sharding\n","    options = tf.data.Options()\n","    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","    tf_dataset = tf_dataset.with_options(options)\n","    \n","    # repeat, batch, prefetch\n","    ds = (\n","        tf_dataset.repeat()\n","        .batch(args.validation_batch_size)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","    \n","    # distribute dataset to devices\n","    return strategy.experimental_distribute_dataset(ds)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section8\"><font color='#FF6F00'><h2>Utility Functions / Class</h2></font></a>\n","\n","- *fix_all_seeds()* - sets the random seed for deterministic results.\n","- *init_logger()* - initialize logger for tracking events.\n","- *ProgressBar()* - custom progress bar to display metrics."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:00:16.844872Z","iopub.status.busy":"2024-05-13T20:00:16.844667Z","iopub.status.idle":"2024-05-13T20:00:16.863063Z","shell.execute_reply":"2024-05-13T20:00:16.862221Z","shell.execute_reply.started":"2024-05-13T20:00:16.844847Z"},"trusted":true},"outputs":[],"source":["def fix_all_seeds(seed):\n","    # set random seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    tf.random.set_seed(seed)\n","    \n","def init_logger(log_file=None, log_file_level=logging.NOTSET):\n","    # initialize logger for tracking events and save in file\n","    if isinstance(log_file, Path):\n","        log_file = str(log_file)\n","    log_format = logging.Formatter(\n","        fmt='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","        datefmt='%m/%d/%Y %H:%M:%S'\n","    )\n","    logger = logging.getLogger()\n","    logger.setLevel(logging.INFO)\n","    console_handler = logging.StreamHandler()\n","    console_handler.setFormatter(log_format)\n","    logger.handlers = [console_handler]\n","    if log_file and log_file != '':\n","        file_handler = logging.FileHandler(log_file)\n","        file_handler.setLevel(log_file_level)\n","        # file_handler.setFormatter(log_format)\n","        logger.addHandler(file_handler)\n","    return logger\n","\n","class ProgressBar(object):\n","    # custom progress bar\n","    def __init__(self, n_total,width=30,desc = 'Training'):\n","        self.width = width\n","        self.n_total = n_total\n","        self.start_time = time.time()\n","        self.desc = desc\n","\n","    def __call__(self, step, info={}):\n","        now = time.time()\n","        current = step + 1\n","        recv_per = current / self.n_total\n","        bar = f'[{self.desc}] {current}/{self.n_total} ['\n","        if recv_per >= 1:\n","            recv_per = 1\n","        prog_width = int(self.width * recv_per)\n","        if prog_width > 0:\n","            bar += '=' * (prog_width - 1)\n","            if current< self.n_total:\n","                bar += \">\"\n","            else:\n","                bar += '='\n","        bar += '.' * (self.width - prog_width)\n","        bar += ']'\n","        show_bar = f\"\\r{bar}\"\n","        time_per_unit = (now - self.start_time) / current\n","        if current < self.n_total:\n","            eta = time_per_unit * (self.n_total - current)\n","            if eta > 3600:\n","                eta_format = ('%d:%02d:%02d' %\n","                              (eta // 3600, (eta % 3600) // 60, eta % 60))\n","            elif eta > 60:\n","                eta_format = '%d:%02d' % (eta // 60, eta % 60)\n","            else:\n","                eta_format = '%ds' % eta\n","            time_info = f' - ETA: {eta_format}'\n","        else:\n","            if time_per_unit >= 1:\n","                time_info = f' {time_per_unit:.1f}s/step'\n","            elif time_per_unit >= 1e-3:\n","                time_info = f' {time_per_unit * 1e3:.1f}ms/step'\n","            else:\n","                time_info = f' {time_per_unit * 1e6:.1f}us/step'\n","\n","        show_bar += time_info\n","        if len(info) != 0:\n","            show_info = f'{show_bar} ' + \\\n","                        \"-\".join([f' {key}: {value:.4f} ' if key != \"learning_rate\" else f' {key}: {value:.8f} ' for key, value in info.items()])\n","            print(show_info, end='')\n","        else:\n","            print(show_bar, end='')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:00:16.864672Z","iopub.status.busy":"2024-05-13T20:00:16.864445Z","iopub.status.idle":"2024-05-13T20:00:16.898344Z","shell.execute_reply":"2024-05-13T20:00:16.897624Z","shell.execute_reply.started":"2024-05-13T20:00:16.864646Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(\n","        self, model, args, train_dataset, validation_dataset, \n","        num_train_examples, num_validation_examples\n","    ):\n","        self.model = model\n","        self.args = args\n","        \n","        self.train_dataset = train_dataset\n","        self.num_train_examples = num_train_examples\n","        \n","        self.validation_dataset = validation_dataset\n","        self.num_validation_examples = num_validation_examples\n","        \n","        self.global_step = 0\n","        self.eval_loss = tf.keras.metrics.Sum()\n","        \n","    def create_optimizer_and_scheduler(self, num_training_steps):\n","        # creates an optimizer with a learning rate schedule using a warmup phase followed by a linear decay.\n","        num_warmup_steps = math.ceil(num_training_steps * self.args.warmup_ratio)\n","        self.optimizer, self.lr_scheduler = create_optimizer(\n","            init_lr=self.args.learning_rate,\n","            num_train_steps=num_training_steps,\n","            num_warmup_steps=num_warmup_steps,\n","            weight_decay_rate=self.args.weight_decay,\n","            adam_epsilon=self.args.adam_epsilon\n","        )\n","    \n","    def evaluation_step(self, features, labels, nb_instances_in_global_batch):\n","        # forward pass\n","        outputs = self.model(input_ids=features['input_ids'], attention_mask=features['attention_mask'], labels=labels, training=False)[:2]\n","        loss, logits = outputs[:2]\n","        # loss scaling\n","        scaled_loss = loss / tf.cast(nb_instances_in_global_batch, dtype=loss.dtype)\n","        # add current batch loss\n","        self.eval_loss.update_state(scaled_loss)\n","    \n","    @tf.function\n","    def distributed_evaluation_steps(self, batch):\n","        features = {k: v for k, v in batch.items() if 'labels' not in k}\n","        labels = batch['labels']\n","        nb_instances = tf.reduce_sum(tf.cast(labels != -100, dtype=tf.int32))\n","        # strategy.run() expects args to be a list or tuple\n","        inputs = (features, labels, nb_instances)\n","        # `run` replicates the provided computation and runs with the distributed input\n","        strategy.run(self.evaluation_step, inputs)\n","\n","    def evaluate(self):\n","        # calculate total validation steps\n","        steps = math.ceil(self.num_validation_examples / self.args.validation_batch_size)\n","        # reset eval loss after every epoch\n","        self.eval_loss.reset_states()\n","        logs = {}\n","        pbar = ProgressBar(n_total=steps, desc='Evaluating')\n","        # iterate over validation dataset\n","        for step, batch in enumerate(self.validation_dataset): \n","            # distributed evaluation step\n","            self.distributed_evaluation_steps(batch) \n","            logs[\"eval_loss\"] = self.eval_loss.result() / (step + 1)\n","            pbar(step=step, info=logs)\n","            if step == steps - 1:\n","                break\n","        print(\"\\n------------- validation result -----------------\")\n","        \n","    def apply_gradients(self, features, labels, nb_instances_in_global_batch):\n","        # forward pass\n","        outputs = self.model(input_ids=features['input_ids'], attention_mask=features['attention_mask'], labels=labels, training=True)[:2] \n","        loss, logits = outputs[:2]\n","        # loss scaling\n","        scaled_loss = loss / tf.cast(nb_instances_in_global_batch, dtype=loss.dtype) \n","        # calculate gradients\n","        gradients = tf.gradients(scaled_loss, self.model.trainable_variables) \n","        # convert gradients with nan value\n","        gradients = [g if g is not None else tf.zeros_like(v) for g, v in zip(gradients, self.model.trainable_variables)] \n","        # optimize the model\n","        self.optimizer.apply_gradients(list(zip(gradients, self.model.trainable_variables))) \n","        # add current batch loss\n","        self.train_loss.update_state(scaled_loss) \n","    \n","    @tf.function\n","    def distributed_training_steps(self, batch):\n","        with strategy.scope():\n","            features = {k: v for k, v in batch.items() if 'labels' not in k}\n","            labels = batch['labels']\n","            nb_instances = tf.reduce_sum(tf.cast(labels != -100, dtype=tf.int32))\n","            # strategy.run() expects args to be a list or tuple\n","            inputs = (features, labels, nb_instances)\n","            # `run` replicates the provided computation and runs with the distributed input.\n","            strategy.run(self.apply_gradients, inputs)\n","    \n","    def train(self):\n","        # calculate total training steps\n","        num_updates_per_epoch = self.num_train_examples // args.train_batch_size \n","        self.steps_per_epoch = num_updates_per_epoch\n","        t_total = self.steps_per_epoch * self.args.epochs\n","        \n","        with strategy.scope():\n","            # optimizer, and checkpoint must be created under `strategy.scope`\n","            # create optimizer and scheduler\n","            self.create_optimizer_and_scheduler(num_training_steps=t_total) \n","            \n","            # create checkpoint manager\n","            folder = os.path.join(self.args.output_dir, self.args.checkpoint_dir)\n","            ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model) \n","            self.model.ckpt_manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n","            iterations = self.optimizer.iterations\n","            \n","            logger.info(\"***** Running training *****\")\n","            logger.info(f\"  Num examples = {self.num_train_examples}\")\n","            logger.info(f\"  Num Epochs = {self.args.epochs}\")\n","            logger.info(f\"  Total train batch size (w. parallel & distributed) = {self.args.train_batch_size * n_replicas(strategy)}\")\n","            logger.info(f\"  Steps per epoch = {self.steps_per_epoch}\")\n","            logger.info(f\"  Total optimization steps = {t_total}\")\n","            \n","            self.train_loss = tf.keras.metrics.Sum(name=\"training_loss\")\n","            start_time = datetime.datetime.now()\n","            for epoch_iter in range(self.args.epochs):\n","                # training loop\n","                logger.info(f\"Epoch {epoch_iter + 1}/{self.args.epochs}\")\n","                \n","                pbar = ProgressBar(n_total=self.steps_per_epoch, desc='Training')\n","                # iterate over training dataset\n","                for step, batch in enumerate(self.train_dataset):    \n","                    # distributed training step\n","                    self.distributed_training_steps(batch) \n","                    \n","                    self.global_step = iterations.numpy()\n","                    training_loss = self.train_loss.result() / (step + 1)\n","                    \n","                    logs = {}\n","                    logs[\"training_loss\"] = training_loss.numpy()\n","                    logs[\"learning_rate\"] = self.lr_scheduler(self.global_step).numpy()\n","                    pbar(step=step, info=logs)\n","                    \n","                    if self.global_step % self.steps_per_epoch == 0:\n","                        print(\"\\n------------- train result -----------------\")\n","                        # call to evaluation loop\n","                        self.evaluate()\n","                        # save checkpoint\n","                        ckpt_save_path = self.model.ckpt_manager.save()\n","                        logger.info(f\"Saving checkpoint at {ckpt_save_path}\")\n","                        break\n","                \n","                # reset train loss after every epoch\n","                self.train_loss.reset_states()\n","            end_time = datetime.datetime.now()\n","            logger.info(f\"Training took: {str(end_time - start_time)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:00:16.900047Z","iopub.status.busy":"2024-05-13T20:00:16.899618Z","iopub.status.idle":"2024-05-13T20:00:16.912120Z","shell.execute_reply":"2024-05-13T20:00:16.911333Z","shell.execute_reply.started":"2024-05-13T20:00:16.900009Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report, confusion_matrix\n","    \n","\n","def run(args):\n","    logger.info(\" Starting training / evaluation\")\n","    \n","    logger.info(\" Downloading Data Files\")\n","    dataset_path = download_dataset(args.cache_dir) \n","\n","    logger.info(\" Loading Data Files\")\n","    dataset = load_dataset('json', data_files=dataset_path) \n","    # train test split\n","    dataset = dataset['train'].train_test_split(0.1, shuffle=False) \n","        \n","    logger.info(\" Initializing Tokenizer\")\n","    tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name) \n","    \n","    logger.info(\" Preparing Features\")\n","    dataset = dataset.map(convert_examples_to_features, batched=True, fn_kwargs={\"tokenizer\":tokenizer, \"args\":args})\n","\n","    logger.info(\" Intializing training and validation dataset \")\n","    train_dataset = dataset['train']\n","    num_train_examples = len(dataset['train'])\n","    # create tf train dataset\n","    tf_train_dataset = get_train_tfdataset(train_dataset, num_train_examples, args) \n","    \n","    validation_dataset = dataset['test']\n","    num_validation_examples = len(dataset['test'])\n","    # create tf validation dataset\n","    tf_validation_dataset = get_validation_tfdataset(train_dataset, num_validation_examples, args) \n","    \n","    logger.info(f' Intializing model | {args.model_type.upper()} ')\n","    with strategy.scope():\n","        # model must be created under `strategy.scope`\n","        model = TFT5ForConditionalGeneration.from_pretrained(args.model_name_or_path, from_pt=True)\n","    \n","    # custom training loop\n","    trainer = Trainer(model, args, tf_train_dataset, tf_validation_dataset, num_train_examples, num_validation_examples) \n","    trainer.train()\n","    \n","    # save pretrained model and tokenizer\n","    logger.info(f\" Saving model in {args.save_dir}\")\n","    trainer.model.save_pretrained(args.save_dir)\n","    tokenizer.save_pretrained(args.save_dir)\n","    \n"]},{"cell_type":"code","execution_count":8,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-13T20:00:16.913330Z","iopub.status.busy":"2024-05-13T20:00:16.913128Z","iopub.status.idle":"2024-05-13T20:18:01.025071Z","shell.execute_reply":"2024-05-13T20:18:01.024387Z","shell.execute_reply.started":"2024-05-13T20:00:16.913305Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["05/13/2024 20:00:16 - INFO - root -    Starting training / evaluation\n","05/13/2024 20:00:16 - INFO - root -    Downloading Data Files\n","05/13/2024 20:00:16 - INFO - root -    Loading Data Files\n","05/13/2024 20:00:17 - WARNING - datasets.builder -   Using custom data configuration default-6bebfd084315724d\n","05/13/2024 20:00:17 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba4122f820104bc2b750d7aaaee12d3f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:00:17 - INFO - root -    Initializing Tokenizer\n","05/13/2024 20:00:20 - INFO - root -    Preparing Features\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5267aa8d46c34b12b4344b22a322410d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91e75956b40a4d208c705aee7e1afdb3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:00:23 - INFO - root -    Intializing training and validation dataset \n","05/13/2024 20:00:23 - INFO - root -    Intializing model | T5 \n","2024-05-13 20:00:24.023836: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","05/13/2024 20:00:27 - INFO - root -   ***** Running training *****\n","05/13/2024 20:00:27 - INFO - root -     Num examples = 876\n","05/13/2024 20:00:27 - INFO - root -     Num Epochs = 20\n","05/13/2024 20:00:27 - INFO - root -     Total train batch size (w. parallel & distributed) = 8\n","05/13/2024 20:00:27 - INFO - root -     Steps per epoch = 109\n","05/13/2024 20:00:27 - INFO - root -     Total optimization steps = 2180\n","05/13/2024 20:00:27 - INFO - root -   Epoch 1/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 3.2s/step  training_loss: 3.6577 - learning_rate: 0.00007500    \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 931.9ms/step  eval_loss: 1.5159 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:06:29 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-1\n","05/13/2024 20:06:29 - INFO - root -   Epoch 2/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.0ms/step  training_loss: 1.5058 - learning_rate: 0.00015000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 5.1s/step  eval_loss: 1.0513  \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:08:08 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-2\n","05/13/2024 20:08:08 - INFO - root -   Epoch 3/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 249.8ms/step  training_loss: 1.2090 - learning_rate: 0.00022500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.9ms/step  eval_loss: 0.8118 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:08:40 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-3\n","05/13/2024 20:08:40 - INFO - root -   Epoch 4/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.2ms/step  training_loss: 0.9871 - learning_rate: 0.00030000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 76.4ms/step  eval_loss: 0.6217 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:09:13 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-4\n","05/13/2024 20:09:13 - INFO - root -   Epoch 5/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 252.8ms/step  training_loss: 0.7962 - learning_rate: 0.00028125 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.4ms/step  eval_loss: 0.4467 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:09:46 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-5\n","05/13/2024 20:09:46 - INFO - root -   Epoch 6/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.3ms/step  training_loss: 0.6252 - learning_rate: 0.00026250 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 76.7ms/step  eval_loss: 0.3205 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:10:19 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-6\n","05/13/2024 20:10:19 - INFO - root -   Epoch 7/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.8ms/step  training_loss: 0.4777 - learning_rate: 0.00024375 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.6ms/step  eval_loss: 0.2422 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:10:52 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-7\n","05/13/2024 20:10:52 - INFO - root -   Epoch 8/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 252.4ms/step  training_loss: 0.3994 - learning_rate: 0.00022500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 73.0ms/step  eval_loss: 0.1652 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:11:25 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-8\n","05/13/2024 20:11:25 - INFO - root -   Epoch 9/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.9ms/step  training_loss: 0.3120 - learning_rate: 0.00020625 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 71.0ms/step  eval_loss: 0.1158 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:11:58 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-9\n","05/13/2024 20:11:58 - INFO - root -   Epoch 10/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 252.1ms/step  training_loss: 0.2364 - learning_rate: 0.00018750 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 71.5ms/step  eval_loss: 0.0638 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:12:31 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-10\n","05/13/2024 20:12:31 - INFO - root -   Epoch 11/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.0ms/step  training_loss: 0.1799 - learning_rate: 0.00016875 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.5ms/step  eval_loss: 0.0457 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:13:03 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-11\n","05/13/2024 20:13:03 - INFO - root -   Epoch 12/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.3ms/step  training_loss: 0.1346 - learning_rate: 0.00015000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.6ms/step  eval_loss: 0.0339 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:13:36 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-12\n","05/13/2024 20:13:36 - INFO - root -   Epoch 13/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.5ms/step  training_loss: 0.1113 - learning_rate: 0.00013125 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 76.8ms/step  eval_loss: 0.0187 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:14:09 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-13\n","05/13/2024 20:14:09 - INFO - root -   Epoch 14/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 252.0ms/step  training_loss: 0.0852 - learning_rate: 0.00011250 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 74.7ms/step  eval_loss: 0.0169 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:14:41 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-14\n","05/13/2024 20:14:41 - INFO - root -   Epoch 15/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.8ms/step  training_loss: 0.0663 - learning_rate: 0.00009375 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.3ms/step  eval_loss: 0.0121 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:15:14 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-15\n","05/13/2024 20:15:14 - INFO - root -   Epoch 16/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.8ms/step  training_loss: 0.0543 - learning_rate: 0.00007500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.5ms/step  eval_loss: 0.0086 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:15:47 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-16\n","05/13/2024 20:15:47 - INFO - root -   Epoch 17/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.8ms/step  training_loss: 0.0456 - learning_rate: 0.00005625 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 72.2ms/step  eval_loss: 0.0039 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:16:20 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-17\n","05/13/2024 20:16:20 - INFO - root -   Epoch 18/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 250.9ms/step  training_loss: 0.0355 - learning_rate: 0.00003750 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 71.1ms/step  eval_loss: 0.0029 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:16:53 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-18\n","05/13/2024 20:16:53 - INFO - root -   Epoch 19/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 249.1ms/step  training_loss: 0.0303 - learning_rate: 0.00001875 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.6ms/step  eval_loss: 0.0024 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:17:25 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-19\n","05/13/2024 20:17:25 - INFO - root -   Epoch 20/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 251.3ms/step  training_loss: 0.0280 - learning_rate: 0.00000000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 76.8ms/step  eval_loss: 0.0020 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:17:58 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-20\n","05/13/2024 20:17:58 - INFO - root -   Training took: 0:17:31.661229\n","05/13/2024 20:17:58 - INFO - root -    Saving model in runs//saved_model/\n"]}],"source":["class Args:\n","    # define training arguments\n","    \n","    # MODEL\n","    model_type = 't5'\n","    tokenizer_name = 'Salesforce/codet5-base'\n","    model_name_or_path = 'Salesforce/codet5-base'\n","    \n","    # DATA\n","    train_batch_size = 8\n","    validation_batch_size = 8\n","    max_input_length = 48\n","    max_target_length = 128\n","    prefix = \"Generate Python: \"    \n","\n","    # OPTIMIZER\n","    learning_rate = 3e-4\n","    weight_decay = 1e-4\n","    warmup_ratio = 0.2\n","    adam_epsilon = 1e-8\n","\n","    # TRAINING\n","    seed = 2022\n","    epochs = 20\n","\n","    # DIRECTORIES\n","    output_dir = \"runs/\"\n","    logging_dir = f\"{output_dir}/logs/\"\n","    checkpoint_dir = f\"checkpoint\"\n","    save_dir = f\"{output_dir}/saved_model/\"\n","    cache_dir = '../working/'\n","    Path(output_dir).mkdir(parents=True, exist_ok=True)\n","    Path(logging_dir).mkdir(parents=True, exist_ok=True)\n","    Path(save_dir).mkdir(parents=True, exist_ok=True)\n","    \n","\n","# initialize training arguments\n","args = Args()\n","# initialize logger\n","logger = init_logger(log_file=os.path.join(args.logging_dir, f\"{args.model_type}-{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}.log\"))\n","# fix all seeds\n","fix_all_seeds(args.seed)\n","\n","if __name__ == \"__main__\":\n","    # run training and evaluation\n","    dataset = run(args)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:18:01.030132Z","iopub.status.busy":"2024-05-13T20:18:01.029892Z","iopub.status.idle":"2024-05-13T20:18:01.042800Z","shell.execute_reply":"2024-05-13T20:18:01.042038Z","shell.execute_reply.started":"2024-05-13T20:18:01.030102Z"},"trusted":true},"outputs":[],"source":["def run_predict(args, text):\n","    # load saved finetuned model\n","    model = TFT5ForConditionalGeneration.from_pretrained(args.save_dir)\n","    # load saved tokenizer\n","    tokenizer = RobertaTokenizer.from_pretrained(args.save_dir) \n","    \n","     # encode texts by prepending the task for input sequence and appending the test sequence\n","    query = args.prefix + text \n","    encoded_text = tokenizer(query, return_tensors='tf', padding='max_length', truncation=True, max_length=args.max_input_length)\n","    \n","    # inference\n","    generated_code = model.generate(\n","        encoded_text[\"input_ids\"], attention_mask=encoded_text[\"attention_mask\"], \n","        max_length=args.max_target_length, top_p=0.95, top_k=50, repetition_penalty=2, num_return_sequences=1\n","    )\n","    \n","    # decode generated tokens\n","    decoded_code = tokenizer.decode(generated_code.numpy()[0], skip_special_tokens=True)\n","    return decoded_code\n","\n","def predict_from_dataset(args):\n","    # load using hf datasets\n","    dataset = load_dataset('json', data_files='../working/mbpp.jsonl') \n","    # train test split\n","    dataset = dataset['train'].train_test_split(0.1, shuffle=False) \n","    test_dataset = dataset['test']\n","    \n","    # randomly select an index from the validation dataset\n","    index = random.randint(0, len(test_dataset))\n","    text = test_dataset[index]['text']\n","    code = test_dataset[index]['code']\n","    \n","    # run-predict on text\n","    decoded_code = run_predict(args, text)\n","    \n","    print(\"#\" * 25); print(\"QUERY: \", text); \n","    print()\n","    print('#' * 25); print(\"ORIGINAL: \"); print(\"\\n\", code);\n","    print()\n","    print('#' * 25); print(\"GENERATED: \"); print(\"\\n\", decoded_code);\n","    \n","def predict_from_text(args, text):\n","    # run-predict on text\n","    decoded_code = run_predict(args, text)\n","    print(\"#\" * 25); print(\"QUERY: \", text); \n","    print()\n","    print('#' * 25); print(\"GENERATED: \"); print(\"\\n\", decoded_code);"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section12a\"><font color='#425066'><h3>Predict from Dataset</h3></font></a>"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-13T20:18:01.044006Z","iopub.status.busy":"2024-05-13T20:18:01.043799Z","iopub.status.idle":"2024-05-13T20:18:32.938526Z","shell.execute_reply":"2024-05-13T20:18:32.937713Z","shell.execute_reply.started":"2024-05-13T20:18:01.043980Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["05/13/2024 20:18:02 - WARNING - datasets.builder -   Using custom data configuration default-6bebfd084315724d\n","05/13/2024 20:18:02 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f79b9a7b32342aaa378a8470f16fe32","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:18:02 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-400ea8910b364fc0.arrow and /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-a008892a66ee5e3b.arrow\n"]},{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to convert the given tuples into set.\n","\n","#########################\n","ORIGINAL: \n","\n"," def tuple_to_set(t):\n","  s = set(t)\n","  return (s) \n","\n","#########################\n","GENERATED: \n","\n"," def tuple_set(testtup):\n","  res = set([tuple() for ele in testT up]) \n","  return (res)\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:18:09 - WARNING - datasets.builder -   Using custom data configuration default-6bebfd084315724d\n","05/13/2024 20:18:09 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43ea917fb4e74476a25a5e11f181771f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:18:09 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-400ea8910b364fc0.arrow and /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-a008892a66ee5e3b.arrow\n"]},{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to check for a number at the end of a string.\n","\n","#########################\n","ORIGINAL: \n","\n"," import re\n","def end_num(string):\n","    text = re.compile(r\".*[0-9]$\")\n","    if text.match(string):\n","        return True\n","    else:\n","        return False\n","\n","#########################\n","GENERATED: \n","\n"," def check_end(str1):\n","    count = 0   for i in range(_len() - 1) : \n","        if str2[i] == '0' and len($list)+count < _max: \n","            return True    \n","    xnumre.search(\"$\", string)) or\\N\" not within the list, int((x / n)]), \"string\") at all (y >= 10)\".split(): \n","         XNUMRE\").sort(), num really=lambda s: bool('inf'))\n"]},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:18:27 - WARNING - datasets.builder -   Using custom data configuration default-6bebfd084315724d\n","05/13/2024 20:18:27 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84679925433a4f5ebaaf36b4e3ae0671","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:18:27 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-400ea8910b364fc0.arrow and /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-a008892a66ee5e3b.arrow\n"]},{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to convert camel case string to snake case string by using regex.\n","\n","#########################\n","ORIGINAL: \n","\n"," import re\n","def camel_to_snake(text):\n","  str1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', text)\n","  return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', str1).lower()\n","\n","#########################\n","GENERATED: \n","\n"," import re\n","def snake_to_camel(word):\n","  return ''.join('_')\n"]}],"source":["# example 1\n","predict_from_dataset(args)\n","# example 2\n","predict_from_dataset(args)\n","# example 3\n","predict_from_dataset(args)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"section12b\"><font color='#425066'><h3>Predict from Text</h3></font></a>"]},{"cell_type":"code","execution_count":11,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-13T20:18:32.940350Z","iopub.status.busy":"2024-05-13T20:18:32.940150Z","iopub.status.idle":"2024-05-13T20:19:03.925480Z","shell.execute_reply":"2024-05-13T20:19:03.924767Z","shell.execute_reply.started":"2024-05-13T20:18:32.940325Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to add two random numbers\n","\n","#########################\n","GENERATED: \n","\n"," def add_random(nums1, nums2):\n","    if len (numbers)==0:\n","        return 0;\n","     else:\\\n","         random = [a for a in range('10',len(_))] + num1[:-count];\n","          yield from listify([int((i / math.log 10), int(\"\".join(map()\", array)))])\n","\n","#########################\n","QUERY:  Write a function to find the frequency of items in a list\n","\n","#########################\n","GENERATED: \n","\n"," import collections\n","def freq_count(list1): \n","    dict = Counter()   for i in list 1: \n","        keys=dict.keys():    \n","            if len (key) == 0 or key[len(*value)] > maxsize : \n","                return -2\n","       result, frequency\n","\n","#########################\n","QUERY:  Write a function to concatenate two dictionary\n","\n","#########################\n","GENERATED: \n","\n"," def concatenate_dict(d1, d2):\n","    return (sorted([x for x in zip(*map(_add__), dict[y]]))\n","\n"]}],"source":["# example 1\n","predict_from_text(args, \"Write a function to add two random numbers\"); print()\n","# example 2\n","predict_from_text(args, \"Write a function to find the frequency of items in a list\"); print()\n","# example 3\n","predict_from_text(args, \"Write a function to concatenate two dictionary\"); print()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:50:18.892021Z","iopub.status.busy":"2024-05-13T20:50:18.891215Z","iopub.status.idle":"2024-05-13T21:06:45.849681Z","shell.execute_reply":"2024-05-13T21:06:45.848884Z","shell.execute_reply.started":"2024-05-13T20:50:18.891961Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["05/13/2024 20:50:19 - WARNING - datasets.builder -   Using custom data configuration default-6bebfd084315724d\n","05/13/2024 20:50:19 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d20527f4fda047b7a1450a7146ab7629","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["05/13/2024 20:50:19 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-400ea8910b364fc0.arrow and /root/.cache/huggingface/datasets/json/default-6bebfd084315724d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-a008892a66ee5e3b.arrow\n"]},{"name":"stdout","output_type":"stream","text":["Predicted  0\n","\n","Predicted  1\n","\n","Predicted  2\n","\n","Predicted  3\n","\n","Predicted  4\n","\n","Predicted  5\n","\n","Predicted  6\n","\n","Predicted  7\n","\n","Predicted  8\n","\n","Predicted  9\n","\n","Predicted  10\n","\n","Predicted  11\n","\n","Predicted  12\n","\n","Predicted  13\n","\n","Predicted  14\n","\n","Predicted  15\n","\n","Predicted  16\n","\n","Predicted  17\n","\n","Predicted  18\n","\n","Predicted  19\n","\n","Predicted  20\n","\n","Predicted  21\n","\n","Predicted  22\n","\n","Predicted  23\n","\n","Predicted  24\n","\n","Predicted  25\n","\n","Predicted  26\n","\n","Predicted  27\n","\n","Predicted  28\n","\n","Predicted  29\n","\n","Predicted  30\n","\n","Predicted  31\n","\n","Predicted  32\n","\n","Predicted  33\n","\n","Predicted  34\n","\n","Predicted  35\n","\n","Predicted  36\n","\n","Predicted  37\n","\n","Predicted  38\n","\n","Predicted  39\n","\n","Predicted  40\n","\n","Predicted  41\n","\n","Predicted  42\n","\n","Predicted  43\n","\n","Predicted  44\n","\n","Predicted  45\n","\n","Predicted  46\n","\n","Predicted  47\n","\n","Predicted  48\n","\n","Predicted  49\n","\n","Predicted  50\n","\n","Predicted  51\n","\n","Predicted  52\n","\n","Predicted  53\n","\n","Predicted  54\n","\n","Predicted  55\n","\n","Predicted  56\n","\n","Predicted  57\n","\n","Predicted  58\n","\n","Predicted  59\n","\n","Predicted  60\n","\n","Predicted  61\n","\n","Predicted  62\n","\n","Predicted  63\n","\n","Predicted  64\n","\n","Predicted  65\n","\n","Predicted  66\n","\n","Predicted  67\n","\n","Predicted  68\n","\n","Predicted  69\n","\n","Predicted  70\n","\n","Predicted  71\n","\n","Predicted  72\n","\n","Predicted  73\n","\n","Predicted  74\n","\n","Predicted  75\n","\n","Predicted  76\n","\n","Predicted  77\n","\n","Predicted  78\n","\n","Predicted  79\n","\n","Predicted  80\n","\n","Predicted  81\n","\n","Predicted  82\n","\n","Predicted  83\n","\n","Predicted  84\n","\n","Predicted  85\n","\n","Predicted  86\n","\n","Predicted  87\n","\n","Predicted  88\n","\n","Predicted  89\n","\n","Predicted  90\n","\n","Predicted  91\n","\n","Predicted  92\n","\n","Predicted  93\n","\n","Predicted  94\n","\n","Predicted  95\n","\n","Predicted  96\n","\n","Predicted  97\n","\n"]}],"source":["\n","\n","# Initialize global lists to store true and predicted values\n","y_true = []\n","y_pred = []\n","\n","def evaluate_from_dataset(args):\n","    global y_true, y_pred  # Declare the lists as global within the function\n","    \n","    # Load dataset\n","    dataset = load_dataset('json', data_files='../working/mbpp.jsonl') \n","    # Train-test split\n","    dataset = dataset['train'].train_test_split(0.1, shuffle=False) \n","    test_dataset = dataset['test']\n","    \n","    # Clear lists before each evaluation\n","    y_true.clear()\n","    y_pred.clear()\n","    \n","    # Initialize lists to store reference and candidate sentences for BLEU calculation\n","    references = []\n","    candidates = []\n","    \n","    # Iterate through test dataset\n","    for i, data in enumerate(test_dataset):\n","        text = data['text']\n","        code = data['code']\n","        \n","        # Run prediction\n","        decoded_code = run_predict(args, text)\n","        \n","        # Append true and predicted values\n","        y_true.append(code)\n","        y_pred.append(decoded_code)\n","        \n","        # Append original and generated code for BLEU score calculation\n","        \n","        print(\"Predicted \", i)\n","        print()\n","\n","    # Calculate evaluation metrics\n","\n","\n","# Call the function\n","evaluate_from_dataset(args)\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:35:33.327544Z","iopub.status.busy":"2024-05-13T20:35:33.327137Z","iopub.status.idle":"2024-05-13T20:35:33.331258Z","shell.execute_reply":"2024-05-13T20:35:33.330489Z","shell.execute_reply.started":"2024-05-13T20:35:33.327499Z"},"trusted":true},"outputs":[],"source":["# %cd /kaggle/working\n","# from IPython.display import FileLink\n","# FileLink('runs/saved_model/tf_model.h5')"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-13T20:35:33.794951Z","iopub.status.busy":"2024-05-13T20:35:33.794732Z","iopub.status.idle":"2024-05-13T20:35:33.799981Z","shell.execute_reply":"2024-05-13T20:35:33.799173Z","shell.execute_reply.started":"2024-05-13T20:35:33.794923Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[\"def sort_String(str) : \\r\\n    str = ''.join(sorted(str)) \\r\\n    return (str) \", 'def check_tuples(test_tuple, K):\\r\\n  res = all(ele in K for ele in test_tuple)\\r\\n  return (res) ', \"import re\\r\\ndef text_match(text):\\r\\n  patterns = 'a.*?b$'\\r\\n  if re.search(patterns,  text):\\r\\n    return ('Found a match!')\\r\\n  else:\\r\\n    return ('Not matched!')\", 'def Check_Solution(a,b,c) : \\r\\n    if ((b*b) - (4*a*c)) > 0 : \\r\\n        return (\"2 solutions\") \\r\\n    elif ((b*b) - (4*a*c)) == 0 : \\r\\n        return (\"1 solution\") \\r\\n    else : \\r\\n        return (\"No solutions\") ', 'def sum_even_odd(list1):\\r\\n    first_even = next((el for el in list1 if el%2==0),-1)\\r\\n    first_odd = next((el for el in list1 if el%2!=0),-1)\\r\\n    return (first_even+first_odd)', 'def parallelogram_perimeter(b,h):\\r\\n  perimeter=2*(b*h)\\r\\n  return perimeter', 'def div_of_nums(nums,m,n):\\r\\n result = list(filter(lambda x: (x % m == 0 and x % n == 0), nums)) \\r\\n return result', 'def all_Bits_Set_In_The_Given_Range(n,l,r): \\r\\n    num = ((1 << r) - 1) ^ ((1 << (l - 1)) - 1) \\r\\n    new_num = n & num \\r\\n    if (num == new_num): \\r\\n        return True\\r\\n    return False', 'def is_Isomorphic(str1,str2):          \\r\\n    dict_str1 = {}\\r\\n    dict_str2 = {}\\r\\n    for i, value in enumerate(str1):\\r\\n        dict_str1[value] = dict_str1.get(value,[]) + [i]        \\r\\n    for j, value in enumerate(str2):\\r\\n        dict_str2[value] = dict_str2.get(value,[]) + [j]\\r\\n    if sorted(dict_str1.values()) == sorted(dict_str2.values()):\\r\\n        return True\\r\\n    else:\\r\\n        return False', 'def sum_num(numbers):\\r\\n    total = 0\\r\\n    for x in numbers:\\r\\n        total += x\\r\\n    return total/len(numbers) ', 'def is_odd(n) : \\r\\n    if (n^1 == n-1) :\\r\\n        return True; \\r\\n    else :\\r\\n        return False; ', 'def substract_elements(test_tup1, test_tup2):\\r\\n  res = tuple(tuple(a - b for a, b in zip(tup1, tup2))\\r\\n   for tup1, tup2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ', 'def reverse_list_lists(lists):\\r\\n    for l in lists:\\r\\n        l.sort(reverse = True)\\r\\n    return lists ', 'def find_Extra(arr1,arr2,n) : \\r\\n    for i in range(0, n) : \\r\\n        if (arr1[i] != arr2[i]) : \\r\\n            return i \\r\\n    return n ', 'def same_Length(A,B): \\r\\n    while (A > 0 and B > 0): \\r\\n        A = A / 10; \\r\\n        B = B / 10; \\r\\n    if (A == 0 and B == 0): \\r\\n        return True; \\r\\n    return False; ', \"import re\\r\\ndef remove_spaces(text):\\r\\n return (re.sub(' +',' ',text))\", 'def Extract(lst): \\r\\n    return [item[-1] for item in lst] ', \"def float_to_tuple(test_str):\\r\\n  res = tuple(map(float, test_str.split(', ')))\\r\\n  return (res) \", 'def max_sum_subseq(A):\\r\\n    n = len(A)\\r\\n    if n == 1:\\r\\n        return A[0]\\r\\n    look_up = [None] * n\\r\\n    look_up[0] = A[0]\\r\\n    look_up[1] = max(A[0], A[1])\\r\\n    for i in range(2, n):\\r\\n        look_up[i] = max(look_up[i - 1], look_up[i - 2] + A[i])\\r\\n        look_up[i] = max(look_up[i], A[i])\\r\\n    return look_up[n - 1]', 'def last(n):\\r\\n   return n[-1]\\r\\ndef sort_list_last(tuples):\\r\\n  return sorted(tuples, key=last)', 'def is_Word_Present(sentence,word): \\r\\n    s = sentence.split(\" \") \\r\\n    for i in s:  \\r\\n        if (i == word): \\r\\n            return True\\r\\n    return False', 'from itertools import groupby \\r\\ndef extract_elements(numbers, n):\\r\\n    result = [i for i, j in groupby(numbers) if len(list(j)) == n] \\r\\n    return result', 'def check(arr,n): \\r\\n    g = 0 \\r\\n    for i in range(1,n): \\r\\n        if (arr[i] - arr[i - 1] > 0 and g == 1): \\r\\n            return False\\r\\n        if (arr[i] - arr[i] < 0): \\r\\n            g = 1\\r\\n    return True', 'import re\\r\\ndef match_num(string):\\r\\n    text = re.compile(r\"^5\")\\r\\n    if text.match(string):\\r\\n        return True\\r\\n    else:\\r\\n        return False', 'def smallest_multiple(n):\\r\\n    if (n<=2):\\r\\n      return n\\r\\n    i = n * 2\\r\\n    factors = [number  for number in range(n, 1, -1) if number * 2 > n]\\r\\n    while True:\\r\\n        for a in factors:\\r\\n            if i % a != 0:\\r\\n                i += n\\r\\n                break\\r\\n            if (a == factors[-1] and i % a == 0):\\r\\n                return i', 'from collections import Counter\\r\\ndef add_dict(d1,d2):\\r\\n   add_dict = Counter(d1) + Counter(d2)\\r\\n   return add_dict', 'def count_Unset_Bits(n) :  \\r\\n    cnt = 0;  \\r\\n    for i in range(1,n + 1) : \\r\\n        temp = i;  \\r\\n        while (temp) :  \\r\\n            if (temp % 2 == 0) : \\r\\n                cnt += 1;  \\r\\n            temp = temp // 2;  \\r\\n    return cnt;  ', 'def even_num(x):\\r\\n  if x%2==0:\\r\\n     return True\\r\\n  else:\\r\\n    return False', 'def factorial(start,end): \\r\\n    res = 1 \\r\\n    for i in range(start,end + 1): \\r\\n        res *= i      \\r\\n    return res \\r\\ndef sum_of_square(n): \\r\\n   return int(factorial(n + 1, 2 * n)  /factorial(1, n)) ', \"import re\\r\\ndef extract_date(url):\\r\\n        return re.findall(r'/(\\\\d{4})/(\\\\d{1,2})/(\\\\d{1,2})/', url)\", 'def lucky_num(n):\\r\\n List=range(-1,n*n+9,2)\\r\\n i=2\\r\\n while List[i:]:List=sorted(set(List)-set(List[List[i]::List[i]]));i+=1\\r\\n return List[1:n+1]', 'def find_fixed_point(arr, n): \\r\\n\\tfor i in range(n): \\r\\n\\t\\tif arr[i] is i: \\r\\n\\t\\t\\treturn i \\r\\n\\treturn -1', 'def previous_palindrome(num):\\r\\n    for x in range(num-1,0,-1):\\r\\n        if str(x) == str(x)[::-1]:\\r\\n            return x', 'import datetime\\r\\ndef check_date(m, d, y):\\r\\n    try:\\r\\n        m, d, y = map(int, (m, d, y))\\r\\n        datetime.date(y, m, d)\\r\\n        return True\\r\\n    except ValueError:\\r\\n        return False', 'def maximum_product(nums):\\r\\n    import heapq\\r\\n    a, b = heapq.nlargest(3, nums), heapq.nsmallest(2, nums)\\r\\n    return max(a[0] * a[1] * a[2], a[0] * b[0] * b[1])', 'def binomial_coeff(n, k): \\r\\n\\tC = [[0 for j in range(k + 1)] \\r\\n\\t\\t\\tfor i in range(n + 1)] \\r\\n\\tfor i in range(0, n + 1): \\r\\n\\t\\tfor j in range(0, min(i, k) + 1): \\r\\n\\t\\t\\tif (j == 0 or j == i): \\r\\n\\t\\t\\t\\tC[i][j] = 1\\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\tC[i][j] = (C[i - 1][j - 1] \\r\\n\\t\\t\\t\\t\\t\\t\\t+ C[i - 1][j]) \\r\\n\\treturn C[n][k] \\r\\ndef lobb_num(n, m): \\r\\n\\treturn (((2 * m + 1) *\\r\\n\\t\\tbinomial_coeff(2 * n, m + n)) \\r\\n\\t\\t\\t\\t\\t/ (m + n + 1))', 'import re\\r\\ndef end_num(string):\\r\\n    text = re.compile(r\".*[0-9]$\")\\r\\n    if text.match(string):\\r\\n        return True\\r\\n    else:\\r\\n        return False', 'def is_Two_Alter(s):  \\r\\n    for i in range (len( s) - 2) : \\r\\n        if (s[i] != s[i + 2]) : \\r\\n            return False\\r\\n    if (s[0] == s[1]): \\r\\n        return False\\r\\n    return True', 'def rearrange_numbs(array_nums):\\r\\n  result = sorted(array_nums, key = lambda i: 0 if i == 0 else -1 / i)\\r\\n  return result ', 'def find_triplet_array(A, arr_size, sum): \\r\\n\\tfor i in range( 0, arr_size-2): \\r\\n\\t\\tfor j in range(i + 1, arr_size-1): \\r\\n\\t\\t\\tfor k in range(j + 1, arr_size): \\r\\n\\t\\t\\t\\tif A[i] + A[j] + A[k] == sum: \\r\\n\\t\\t\\t\\t\\treturn  A[i],A[j],A[k] \\r\\n\\t\\t\\t\\t\\treturn True\\r\\n\\treturn False', \"import re\\r\\ndef text_uppercase_lowercase(text):\\r\\n        patterns = '[A-Z]+[a-z]+$'\\r\\n        if re.search(patterns, text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return ('Not matched!')\", 'def coin_change(S, m, n): \\r\\n    table = [[0 for x in range(m)] for x in range(n+1)] \\r\\n    for i in range(m): \\r\\n        table[0][i] = 1\\r\\n    for i in range(1, n+1): \\r\\n        for j in range(m): \\r\\n            x = table[i - S[j]][j] if i-S[j] >= 0 else 0\\r\\n            y = table[i][j-1] if j >= 1 else 0 \\r\\n            table[i][j] = x + y   \\r\\n    return table[n][m-1] ', 'def multiply_list(items):\\r\\n    tot = 1\\r\\n    for x in items:\\r\\n        tot *= x\\r\\n    return tot', 'def remove_tuple(test_list):\\r\\n  res = [sub for sub in test_list if not all(ele == None for ele in sub)]\\r\\n  return (str(res)) ', 'def chunk_tuples(test_tup, N):\\r\\n  res = [test_tup[i : i + N] for i in range(0, len(test_tup), N)]\\r\\n  return (res) ', 'def max_product(arr): \\r\\n    arr_len = len(arr) \\r\\n    if (arr_len < 2): \\r\\n        return None     \\r\\n    x = arr[0]; y = arr[1]    \\r\\n    for i in range(0, arr_len): \\r\\n        for j in range(i + 1, arr_len): \\r\\n            if (arr[i] * arr[j] > x * y): \\r\\n                x = arr[i]; y = arr[j] \\r\\n    return x,y   ', 'def super_seq(X, Y, m, n):\\r\\n\\tif (not m):\\r\\n\\t\\treturn n\\r\\n\\tif (not n):\\r\\n\\t\\treturn m\\r\\n\\tif (X[m - 1] == Y[n - 1]):\\r\\n\\t\\treturn 1 + super_seq(X, Y, m - 1, n - 1)\\r\\n\\treturn 1 + min(super_seq(X, Y, m - 1, n),\\tsuper_seq(X, Y, m, n - 1))', 'def max_of_two( x, y ):\\r\\n    if x > y:\\r\\n        return x\\r\\n    return y', 'def mutiple_tuple(nums):\\r\\n    temp = list(nums)\\r\\n    product = 1 \\r\\n    for x in temp:\\r\\n        product *= x\\r\\n    return product', 'def binomial_coeffi(n, k): \\r\\n\\tif (k == 0 or k == n): \\r\\n\\t\\treturn 1\\r\\n\\treturn (binomial_coeffi(n - 1, k - 1) \\r\\n\\t\\t+ binomial_coeffi(n - 1, k)) \\r\\ndef rencontres_number(n, m): \\r\\n\\tif (n == 0 and m == 0): \\r\\n\\t\\treturn 1\\r\\n\\tif (n == 1 and m == 0): \\r\\n\\t\\treturn 0\\r\\n\\tif (m == 0): \\r\\n\\t\\treturn ((n - 1) * (rencontres_number(n - 1, 0)+ rencontres_number(n - 2, 0))) \\r\\n\\treturn (binomial_coeffi(n, m) * rencontres_number(n - m, 0))', 'class Node: \\r\\n\\tdef __init__(self, data): \\r\\n\\t\\tself.data = data \\r\\n\\t\\tself.left = None\\r\\n\\t\\tself.right = None\\r\\ndef max_height(node): \\r\\n\\tif node is None: \\r\\n\\t\\treturn 0 ; \\r\\n\\telse : \\r\\n\\t\\tleft_height = max_height(node.left) \\r\\n\\t\\tright_height = max_height(node.right) \\r\\n\\t\\tif (left_height > right_height): \\r\\n\\t\\t\\treturn left_height+1\\r\\n\\t\\telse: \\r\\n\\t\\t\\treturn right_height+1', \"import re\\r\\ndef change_date_format(dt):\\r\\n        return re.sub(r'(\\\\d{4})-(\\\\d{1,2})-(\\\\d{1,2})', '\\\\\\\\3-\\\\\\\\2-\\\\\\\\1', dt)\\r\\n        return change_date_format(dt)\", 'def count_tuplex(tuplex,value):  \\r\\n  count = tuplex.count(value)\\r\\n  return count', \"import re\\r\\ndef text_match(text):\\r\\n        patterns = 'ab*?'\\r\\n        if re.search(patterns,  text):\\r\\n                return ('Found a match!')\\r\\n        else:\\r\\n                return ('Not matched!')\", 'import math \\r\\ndef sum_series(number):\\r\\n total = 0\\r\\n total = math.pow((number * (number + 1)) /2, 2)\\r\\n return total', 'def remove_duplic_list(l):\\r\\n    temp = []\\r\\n    for x in l:\\r\\n        if x not in temp:\\r\\n            temp.append(x)\\r\\n    return temp', \"import re\\r\\ndef camel_to_snake(text):\\r\\n  str1 = re.sub('(.)([A-Z][a-z]+)', r'\\\\1_\\\\2', text)\\r\\n  return re.sub('([a-z0-9])([A-Z])', r'\\\\1_\\\\2', str1).lower()\", 'def dealnnoy_num(n, m): \\r\\n\\tif (m == 0 or n == 0) : \\r\\n\\t\\treturn 1\\r\\n\\treturn dealnnoy_num(m - 1, n) + dealnnoy_num(m - 1, n - 1) + dealnnoy_num(m, n - 1)', 'def series_sum(number):\\r\\n total = 0\\r\\n total = (number * (number + 1) * (2 * number + 1)) / 6\\r\\n return total', 'def re_arrange_tuples(test_list, ord_list):\\r\\n  temp = dict(test_list)\\r\\n  res = [(key, temp[key]) for key in ord_list]\\r\\n  return (res) ', 'from collections import Counter \\r\\ndef max_char(str1):\\r\\n    temp = Counter(str1) \\r\\n    max_char = max(temp, key = temp.get)\\r\\n    return max_char', 'import sys \\r\\n\\r\\ndef find_closet(A, B, C, p, q, r): \\r\\n\\tdiff = sys.maxsize \\r\\n\\tres_i = 0\\r\\n\\tres_j = 0\\r\\n\\tres_k = 0\\r\\n\\ti = 0\\r\\n\\tj = 0\\r\\n\\tk = 0\\r\\n\\twhile(i < p and j < q and k < r): \\r\\n\\t\\tminimum = min(A[i], min(B[j], C[k])) \\r\\n\\t\\tmaximum = max(A[i], max(B[j], C[k])); \\r\\n\\t\\tif maximum-minimum < diff: \\r\\n\\t\\t\\tres_i = i \\r\\n\\t\\t\\tres_j = j \\r\\n\\t\\t\\tres_k = k \\r\\n\\t\\t\\tdiff = maximum - minimum; \\r\\n\\t\\tif diff == 0: \\r\\n\\t\\t\\tbreak\\r\\n\\t\\tif A[i] == minimum: \\r\\n\\t\\t\\ti = i+1\\r\\n\\t\\telif B[j] == minimum: \\r\\n\\t\\t\\tj = j+1\\r\\n\\t\\telse: \\r\\n\\t\\t\\tk = k+1\\r\\n\\treturn A[res_i],B[res_j],C[res_k]', \"def sorted_models(models):\\r\\n sorted_models = sorted(models, key = lambda x: x['color'])\\r\\n return sorted_models\", 'def heap_sort(arr):\\r\\n    heapify(arr)  \\r\\n    end = len(arr) - 1\\r\\n    while end > 0:\\r\\n        arr[end], arr[0] = arr[0], arr[end]\\r\\n        shift_down(arr, 0, end - 1)\\r\\n        end -= 1\\r\\n    return arr\\r\\n\\r\\ndef heapify(arr):\\r\\n    start = len(arr) // 2\\r\\n    while start >= 0:\\r\\n        shift_down(arr, start, len(arr) - 1)\\r\\n        start -= 1\\r\\ndef shift_down(arr, start, end):\\r\\n    root = start\\r\\n    while root * 2 + 1 <= end:\\r\\n        child = root * 2 + 1\\r\\n        if child + 1 <= end and arr[child] < arr[child + 1]:\\r\\n            child += 1\\r\\n        if child <= end and arr[root] < arr[child]:\\r\\n            arr[root], arr[child] = arr[child], arr[root]\\r\\n            root = child\\r\\n        else:\\r\\n            return\\r\\n', 'def count_elim(num):\\r\\n  count_elim = 0\\r\\n  for n in num:\\r\\n    if isinstance(n, tuple):\\r\\n        break\\r\\n    count_elim += 1\\r\\n  return count_elim', 'def check_element(test_tup, check_list):\\r\\n  res = False\\r\\n  for ele in check_list:\\r\\n    if ele in test_tup:\\r\\n      res = True\\r\\n      break\\r\\n  return (res) ', 'from heapq import merge\\r\\ndef combine_lists(num1,num2):\\r\\n  combine_lists=list(merge(num1, num2))\\r\\n  return combine_lists', 'import re\\r\\ndef num_position(text):\\r\\n for m in re.finditer(\"\\\\d+\", text):\\r\\n    return m.start()', 'def tuple_to_set(t):\\r\\n  s = set(t)\\r\\n  return (s) ', 'from collections import Counter \\r\\ndef most_common_elem(s,a):\\r\\n  most_common_elem=Counter(s).most_common(a)\\r\\n  return most_common_elem', 'def len_log(list1):\\r\\n    min=len(list1[0])\\r\\n    for i in list1:\\r\\n        if len(i)<min:\\r\\n            min=len(i)\\r\\n    return min', 'def get_item(tup1,index):\\r\\n  item = tup1[index]\\r\\n  return item', 'def count_digs(tup):\\r\\n  return sum([len(str(ele)) for ele in tup ]) \\r\\ndef sort_list(test_list):\\r\\n  test_list.sort(key = count_digs)\\r\\n  return (str(test_list))', \"def chinese_zodiac(year):\\r\\n if (year - 2000) % 12 == 0:\\r\\n     sign = 'Dragon'\\r\\n elif (year - 2000) % 12 == 1:\\r\\n     sign = 'Snake'\\r\\n elif (year - 2000) % 12 == 2:\\r\\n     sign = 'Horse'\\r\\n elif (year - 2000) % 12 == 3:\\r\\n     sign = 'sheep'\\r\\n elif (year - 2000) % 12 == 4:\\r\\n     sign = 'Monkey'\\r\\n elif (year - 2000) % 12 == 5:\\r\\n     sign = 'Rooster'\\r\\n elif (year - 2000) % 12 == 6:\\r\\n     sign = 'Dog'\\r\\n elif (year - 2000) % 12 == 7:\\r\\n     sign = 'Pig'\\r\\n elif (year - 2000) % 12 == 8:\\r\\n     sign = 'Rat'\\r\\n elif (year - 2000) % 12 == 9:\\r\\n     sign = 'Ox'\\r\\n elif (year - 2000) % 12 == 10:\\r\\n     sign = 'Tiger'\\r\\n else:\\r\\n     sign = 'Hare'\\r\\n return sign\", 'def max_similar_indices(test_list1, test_list2):\\r\\n  res = [(max(x[0], y[0]), max(x[1], y[1]))\\r\\n   for x, y in zip(test_list1, test_list2)]\\r\\n  return (res) ', 'def nCr_mod_p(n, r, p): \\r\\n\\tif (r > n- r): \\r\\n\\t\\tr = n - r \\r\\n\\tC = [0 for i in range(r + 1)] \\r\\n\\tC[0] = 1 \\r\\n\\tfor i in range(1, n + 1): \\r\\n\\t\\tfor j in range(min(i, r), 0, -1): \\r\\n\\t\\t\\tC[j] = (C[j] + C[j-1]) % p \\r\\n\\treturn C[r] ', 'def subset(ar, n): \\r\\n    res = 0\\r\\n    ar.sort() \\r\\n    for i in range(0, n) : \\r\\n        count = 1\\r\\n        for i in range(n - 1): \\r\\n            if ar[i] == ar[i + 1]: \\r\\n                count+=1\\r\\n            else: \\r\\n                break \\r\\n        res = max(res, count)  \\r\\n    return res ', 'def profit_amount(actual_cost,sale_amount): \\r\\n if(actual_cost > sale_amount):\\r\\n    amount = actual_cost - sale_amount\\r\\n    return amount\\r\\n else:\\r\\n    return None', 'def is_abundant(n):\\r\\n    fctrsum = sum([fctr for fctr in range(1, n) if n % fctr == 0])\\r\\n    return fctrsum > n', \"import re\\r\\ndef split_list(text):\\r\\n  return (re.findall('[A-Z][^A-Z]*', text))\", 'import math\\r\\ndef get_First_Set_Bit_Pos(n):\\r\\n     return math.log2(n&-n)+1', 'def int_to_roman( num):\\r\\n        val = [1000, 900, 500, 400,100, 90, 50, 40,10, 9, 5, 4,1]\\r\\n        syb = [\"M\", \"CM\", \"D\", \"CD\",\"C\", \"XC\", \"L\", \"XL\",\"X\", \"IX\", \"V\", \"IV\",\"I\"]\\r\\n        roman_num = \\'\\'\\r\\n        i = 0\\r\\n        while  num > 0:\\r\\n            for _ in range(num // val[i]):\\r\\n                roman_num += syb[i]\\r\\n                num -= val[i]\\r\\n            i += 1\\r\\n        return roman_num', 'def Average(lst): \\r\\n    return sum(lst) / len(lst) ', 'def get_noOfways(n):\\r\\n    if (n == 0):\\r\\n        return 0;\\r\\n    if (n == 1):\\r\\n        return 1; \\r\\n    return get_noOfways(n - 1) + get_noOfways(n - 2);', \"def roman_to_int(s):\\r\\n        rom_val = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\\r\\n        int_val = 0\\r\\n        for i in range(len(s)):\\r\\n            if i > 0 and rom_val[s[i]] > rom_val[s[i - 1]]:\\r\\n                int_val += rom_val[s[i]] - 2 * rom_val[s[i - 1]]\\r\\n            else:\\r\\n                int_val += rom_val[s[i]]\\r\\n        return int_val\", 'def sum_Natural(n): \\r\\n    sum = (n * (n + 1)) \\r\\n    return int(sum) \\r\\ndef sum_Even(l,r): \\r\\n    return (sum_Natural(int(r / 2)) - sum_Natural(int((l - 1) / 2))) ', 'def discriminant_value(x,y,z):\\r\\n    discriminant = (y**2) - (4*x*z)\\r\\n    if discriminant > 0:\\r\\n        return (\"Two solutions\",discriminant)\\r\\n    elif discriminant == 0:\\r\\n        return (\"one solution\",discriminant)\\r\\n    elif discriminant < 0:\\r\\n        return (\"no real solution\",discriminant)', \"def word_len(s): \\r\\n    s = s.split(' ')   \\r\\n    for word in s:    \\r\\n        if len(word)%2==0: \\r\\n            return True  \\r\\n        else:\\r\\n          return False\", \"def camel_to_snake(text):\\r\\n        import re\\r\\n        str1 = re.sub('(.)([A-Z][a-z]+)', r'\\\\1_\\\\2', text)\\r\\n        return re.sub('([a-z0-9])([A-Z])', r'\\\\1_\\\\2', str1).lower()\", \"def remove_empty(tuple1): #L = [(), (), ('',), ('a', 'b'), ('a', 'b', 'c'), ('d')]\\r\\n   tuple1 = [t for t in tuple1 if t]\\r\\n   return tuple1\", 'def check(string): \\r\\n  if len(set(string).intersection(\"AEIOUaeiou\"))>=5: \\r\\n    return (\\'accepted\\') \\r\\n  else: \\r\\n    return (\"not accepted\") ', 'def floor_Max(A,B,N):\\r\\n    x = min(B - 1,N)\\r\\n    return (A*x) // B', 'def join_tuples(test_list):\\r\\n  res = []\\r\\n  for sub in test_list:\\r\\n    if res and res[-1][0] == sub[0]:\\r\\n      res[-1].extend(sub[1:])\\r\\n    else:\\r\\n      res.append([ele for ele in sub])\\r\\n  res = list(map(tuple, res))\\r\\n  return (res) ', 'def min_of_two( x, y ):\\r\\n    if x < y:\\r\\n        return x\\r\\n    return y', 'def maximum_segments(n, a, b, c) : \\r\\n\\tdp = [-1] * (n + 10) \\r\\n\\tdp[0] = 0\\r\\n\\tfor i in range(0, n) : \\r\\n\\t\\tif (dp[i] != -1) : \\r\\n\\t\\t\\tif(i + a <= n ): \\r\\n\\t\\t\\t\\tdp[i + a] = max(dp[i] + 1, \\r\\n\\t\\t\\t\\t\\t\\t\\tdp[i + a]) \\r\\n\\t\\t\\tif(i + b <= n ): \\r\\n\\t\\t\\t\\tdp[i + b] = max(dp[i] + 1, \\r\\n\\t\\t\\t\\t\\t\\t\\tdp[i + b]) \\r\\n\\t\\t\\tif(i + c <= n ): \\r\\n\\t\\t\\t\\tdp[i + c] = max(dp[i] + 1, \\r\\n\\t\\t\\t\\t\\t\\t\\tdp[i + c]) \\r\\n\\treturn dp[n]', 'def concatenate_nested(test_tup1, test_tup2):\\r\\n  res = test_tup1 + test_tup2\\r\\n  return (res) ', 'def left_rotate(s,d):\\r\\n    tmp = s[d : ] + s[0 : d]\\r\\n    return tmp  ', 'def min_sum_path(A): \\r\\n\\tmemo = [None] * len(A) \\r\\n\\tn = len(A) - 1\\r\\n\\tfor i in range(len(A[n])): \\r\\n\\t\\tmemo[i] = A[n][i] \\r\\n\\tfor i in range(len(A) - 2, -1,-1): \\r\\n\\t\\tfor j in range( len(A[i])): \\r\\n\\t\\t\\tmemo[j] = A[i][j] + min(memo[j], \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tmemo[j + 1]) \\r\\n\\treturn memo[0]']\n"]}],"source":["print(y_true)"]},{"cell_type":"code","execution_count":63,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-13T21:41:55.350827Z","iopub.status.busy":"2024-05-13T21:41:55.350531Z","iopub.status.idle":"2024-05-13T21:41:55.356051Z","shell.execute_reply":"2024-05-13T21:41:55.355224Z","shell.execute_reply.started":"2024-05-13T21:41:55.350795Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['def sort_String(str1):\\r\\n    result = sorted([x for x in str 1 if not y] ) \\r\\n    return string', 'def check_only(testtup, K):\\r\\n  res = True \\r\\n  for ele in testTdown:\\r\\n    if not isinstance (ele, tuple)) :\\r\\n      break\\r\\n  return False', 'import re\\r\\ndef text_startab(text):\\r\\n  patterns = \\'ab{2,3}\\'\\r\\n ifre.search(\"\", data)):\\r\\n    return (\\'Found a match!\\')\\r\\n else:\\\\\\r\\n     for i in range(\\'0\\',len(*patterns)-1),\\\\', 'def Check_Solution(a,b): \\r\\n    if (2*B * b == 9) :\\r\\n        return (\"Yes\");   else:\\r\\n            solution = 1;    \\r\\n    for i in range((3*(4-bit+1)*10 + ((6**i - 2)) % B);      \\r\\n          result +=(\"No\") ', 'def sum_even(list1):\\r\\n    first = next((el for el in list2 if e% 2==0),- 1)\\r\\n     return (first[sum] )', 'def parallelogram_perimeter(b,h):\\r\\n  perimeter=2*a+w*(i + h)\\r\\n returnPerimeter', 'def div_of(nums,m-n):\\r\\n result = list (filter((lambda x: ((x % m == 0) and (\"No such number\"), nums)) \\r\\n returnresult', 'def all_Bits(n,l):\\r\\n    num = (((1 << l) - 1)) + ((2 ** n ) >> 2); \\r\\n        return True; ', 'def are_Isomorphic(str1, str2):\\r\\n  n = len((v) for v in range (n)) \\r\\n\\tif ((i % 2!= 0),-sys.maxsize - 1);\\r\\n  return True;', 'def add_num(numbers):  \\r\\n    total = 1; \\r\\n    for x in numbers:total *=x    \\r\\n        summ += num      \\r\\n    return (sum m / len([-1])) ', 'def is_Odd(n) : \\r\\n    if (len([i for i in range((1, n+ 1)) == 0]) or\\r\\n        return True;  ', 'def substract_elements(test_tup):\\r\\n  res = tuple() \\r\\n  for ele in test_ t up:\\r\\n    if not isinstance (ele,tuple)) :\\r\\n      return False\\r\\n     else:\\\\\\r\\n       temp.append((sub[0], sub[-1]))*res)  \\r\\n  result += [el] * arr[:-2];\\r\\n  return ((result), key=lambda x: ~x);', 'def reverse_list(inputList):\\r\\n    return [x[::-1] for x in input list () ]', 'def find_Extra(arr,n) : \\r\\n    low = 0\\r\\n        high=0\\r\\n    res = -1  \\r\\n    while (low <= right):     \\r\\n        mid += 1;    \\r\\n        if arr[mid] == item:           \\r\\n            result |= max((high-left)*key(), array([index for index in range(_if n > left]) and remove() fast enough()) \"\\'\".join(\" \".split(\\'\")))\": \\r\\n                return i      ', 'def same_Num(x,y):\\r\\n    return (z == x)', \"import re\\r\\ndef remove_multiplespaces(text1): \\r\\n  return (re.sub(' +',' ', text 1))\", 'def Extract(lst): \\r\\n    return [item[len() - 1] for item in lst ] ', 'def float_to_tuple(test_str):\\r\\n  res = tuple((int(\"\".join([idx for idx in test _iter() if type(\\'.\\'.split (type) == \\'f\\' else -1)) \\r\\n\\t\\t\\t\\tfor jn, tup of stri])\\r\\n   return ((res[0][j] + 1)*lenghts), 2 * lengs())', \"def max_sum (arr, n): \\r\\n\\tMSIBS = arr[:] \\r\\n\\t\\t\\tfor i in range(1,n: \\r\\n\\t\\t\\t\\tif ((i + 1) <= MSB S or ('I', 0)) : \\r\\n\\t\\t\\t\\t\\tMSDBT [0][j]+=array[idx]*m\\r\\n\\t\\t\\t\\t\\t\\telse:: \\r\\n      \\tmsbt += a*e \\r\\n    return msbc\", 'def sort_tuple(tup): \\r\\n\\tlst = len (tru)\\r\\n\\tfor i in range(_len, 0, -1 ): \\r\\n\\t\\t\\tif tup[j] > t up[- 1]: \\r\\n\\t\\t\\t\\ttemp=text[:-2], temp+ttuf[[0]] \\r\\n\\t\\t\\t\\t\\ttsm.append((stri(), tn)[self::-%s]) \\r\\n\\t\\t\\t\\t\\treturn tsms', \"def is_Word(s):\\r\\n  if any (words in s for wordin re.findall('\\\\w+', w)): \\r\\n    return True;  \", 'def extract_continuously(list1, N):\\r\\n    result = [i for i in list2 if type([idx] * n)!= len((arr[0])) - 1]) \\r\\n            returnresult', 'def is_Corner(arr,n): \\r\\n    for i in range (0, n) :\\r\\n        if arr[i] < arr[-1]:     \\r\\n            return True;  \\r\\n    else:    \\r\\n          returns False;\"', \"def string_startwithnum(str, str1):\\r\\n start with num=regex.compile('\\\\w+')\\r\\n end = '' \\r\\n for i in range(_len($string)):\\r\\n    if (i == '0' and replace!= 0),-2]:\\r\\n        return ('Yes')\\r\\n else:'No',x);\", 'def smallest_multiple(n):\\r\\n  return (int)(math.sqrt((1 + n)) / 2)', 'def combine_dict(d1, d2):\\r\\n    result = {key: value for (k, v) in zip(*map(_set__), dict()).items()} \\r\\n    returnResult', 'def count_unset_bits(n): \\r\\n    n += 1; prod = [1] * (pow((2, i) - 2))];  \\r\\n        cnt= 0;\\\\      \\r\\n        while ((temp >0),\" \" ):     \\r\\n            if not in range([True for kin r when temp % N]) :    \\r\\n                break          \\r\\n          res |= getSetBits[k][-1]+getUnsetBit()        \\r\\n                    return incr ', 'def even_position(n) : \\r\\n\\tif (len([i for i in range((2, len() - 1)) % 2!= 0),-1):\\r\\n\\t\\t\\treturn True;  \\r\\n\\telse:\\r\\n\\t\\t\\t\\t return False;\\\\', 'def binomial_Coeff(n,k): \\r\\n    C = [0] * (K + 1);  \\r\\n    for i in range(_+1), 0,-1:    \\r\\n        if k== n : \\r\\n            break;      \\r\\n        else: \\r\\n            B[i][j].append((B[$int() - K]+C) // 2));         \\r\\n        return CB[:N]; ', 'import re\\r\\ndef extract_year(str1): \\r\\n\\tmonth = match(\"[A-Z]\", str2) or \"March\" pattern=\"([a - z0]*)\"\\\\r?\\\\n\".join(\\' \\', i), \")  \\r\\n\\t\\t\\tif month in (\\'January\\', \\'Februar\\', \\'): \\r\\n\\t\\t\\t\\treturn (\"The given date\") \\r\\n\\t\\t\\t\\t\\t\\telse : \\r\\n\\t\\t\\t\\t\\t return \"\"', 'def first_lucky(n): \\r\\n\\tif n <= 2:\\r\\n\\t\\t\\treturn \"Load\" elif (len() == 0)) and arr[0]==1 :\\r\\n\\t\\t\\t\\treturns \"[]\"\\r\\n\\telse:\\\\\\r\\n\\t\\t\\t\\t\\tyield \"\".join([i for i in range(-2, len(\"\") + 1])[:-3], ludic)', 'def find_fixed(a, b): \\r\\n\\tx = (b * a) // 2\\r\\n\\t\\t return x ', 'import sys\\r\\ndef previous_palindrome(num): \\r\\n    numstr = str((int)(sys.maxsize - 1) + 3)*1000);  \\r\\n    return (x,n+1.) ', 'import re\\r\\ndef is_gregorian(dt): \\r\\n\\treturn (re.search(\"[A-Z]\", dt))', \"import heapq as hQ\\r\\ndef max_product(nums,n):\\r\\n  result = [hB*a for a in range (1,' n' + 1)] \\r\\n  return list()\", 'def find_lobbnum(l, m): \\r\\n\\tif (m >= n or ln == 0 and loBBNumber < 1) :\\r\\n\\t\\t\\treturn -1;  \\r\\n\\telse:\\r\\n\\t\\t\\t\\treturns l+n-2*b + get_longest(_sidebars(), 2 * b))', 'def check_end(str1):\\r\\n    count = 0   for i in range(_len() - 1) : \\r\\n        if str2[i] == \\'0\\' and len($list)+count < _max: \\r\\n            return True    \\r\\n    xnumre.search(\"$\", string)) or\\\\N\" not within the list, int((x / n)]), \"string\") at all (y >= 10)\".split(): \\r\\n         XNUMRE\").sort(), num really=lambda s: bool(\\'inf\\'))', 'def check_Equality(str): \\r\\n    if (len([i for i in range((int)(math.sqrt() + 1) / 2)) % 4!= 0),-1, -2);  \\r\\n        else: \\r\\n            return (\"Yes\"); ', 'def rearrange_nums(arr, n):\\r\\n  result = list()\\r\\n  for i in range(_num1(), _no2), 0: \\r\\n    if arr[i] <0 or nums[$id]:\\r\\n      temp.append((temp>>=index) & -count)[idx])\\r\\n   return (result))', 'def check_triplet(A, n, sum):\\r\\n    if count == 3 and not (n & 1) : \\r\\n        return True     elifcount > 2:     \\r\\n      return False   else:\\\\\\r\\n          check _setitem = set() | getvalue([i for i in Aif] + a[0]) % len(\"$\", 0)) or\\\\\\r\\n            all[$#@][idx]+=1;\\r\\n                returns true ', 'def match(text): \\r\\n\\tpattern = \\'[A-Z]+[a-z]*$\\'\\r\\n\\t\\t\\tif re.search(\"^([ a - z])\", text)): \\r\\n\\t\\t\\t\\treturn(\\'Yes\\') \\r\\n\\telse:\\'No\\',Text)   return (\\'no\\')) ', 'def count_coinchange(number):\\r\\n    if (type() == type([]), len(\\'0\\') else 0, -1) \\r\\n        return sum(\"\".join((int)(x[::-2]) + 1))', 'def multiply_items(list1,m):\\r\\n    result = [i*j for i in list2] \\r\\n    returnresult', 'def remove_none(testlist):\\r\\n  res = [ele for sub in test list if ele notin dict.values()] \\r\\n  return (res)', 'def chunk_tuples(testlist, N):\\r\\n  res = [lambda x: (x ** n) for y in test list] \\r\\n  return str((res))', 'def max_Product(arr): \\r\\n\\tn = len(\\'\\'.join([abs (x * y) for x, Y in zip(*nums)))   \\r\\n\\t\\t\\treturn (\"No pairs exists\")           ', 'def longest_subseq(str1, str2): \\r\\n\\tn = len([i for i in range (N + 1)]);\\r\\n\\t\\t\\tif n == 0 or arr[0]!=\\'\\'.join(\"\".split())): \\r\\n\\t\\t\\t\\treturn \"No string exists!\"; \\r\\n  else:\"Do not have a length of this module.\".\\\\', 'def maximum(a,b):   \\r\\n    if a >= b: \\r\\n        return A      \\r\\n     else::NODEVICE res = max((int)(c - (d + 1) * B), 0))  \\r\\n   return str(\"\".join([str(_i(), r for i in range(){}])', 'def product_tuple(nums):\\r\\n    result = 1 for num in zip(* nums)]\\r\\n        return (result *num)', 'def find_rencontres(n): \\r\\n\\treturn (6 * n + 1) ', 'def height_tree(root):\\r\\n\\theight = 0 \\r\\n\\t\\t\\tif root is None:\\r\\n\\t\\t\\t\\treturn 1   \\r\\n\\telse::\\r\\n\\tresult1, result2 += max((min(),max))%len(*) if tree[0] == rootPath else -1\\r\\n\\t return output', \"import re\\r\\ndef change_date(dt):\\r\\n        return date.replace('(\\\\d{4})-([a -z]).*\\\\1', '\\\\\\\\3-\\\\\\\\2\\\\\\\\5')\", 'def count_repeated(testlist):\\r\\n  res = {} \\r\\n  for ele in testlists:    \\r\\n    if not isinstance((ele, tuple)) :\\r\\n      break  \\r\\n    temp, counts |= 1;\\r\\n  return (res)', 'import re\\r\\ndef text_match(text):\\r\\n  patterns = \\'ab+?\\'\\r\\n  ifre.search(\"[a-zA -Z0]+\", data)): \\r\\n    return (\\'Found a match!\\') else:\\\\NOSONIC for i in range(_lenght, _sumt__), 0 or \\\\n\\' + (regex%i)[B]]) :  \\r\\n           (\\'Not matched.\\').append((pattern % d)])))\\telse:\\'\\'.join([patterns])));return (\"Yes\")', 'def sum_series(n):\\r\\n  sm = 0 \\r\\n\\tfor i in range (1, n + 1) :\\r\\n    if ((i * k == 2)] and (\"+j*k== \"+\"):\\r\\n      musicalSum += Mcs[0] ** 3\\r\\n  returnsmath', 'def remove_duplicate(list1):\\r\\n    list.sort()   for item in  set-words():\\r\\n        ifitem notin lists:\\r\\n            return None     else:\\\\\\r\\n        , \\'None\\'\\r\\n       result = [x] + \\'\\'\\r\\n    temp = []\\r\\n    while len(\\'\\'.join([wrdfor wnd of items]))\\r\\n         new_str=new(\"\".split())[:len(-2)]\\r\\n      a += b \\r\\n           j -= 1\\r\\n    add', \"import re\\r\\ndef snake_to_camel(word):\\r\\n  return ''.join('_')\", 'def delannoy_num(n): \\r\\n\\treturn (2 * n + 1) / 2', 'def sum_series(n):\\r\\n  sm = 0 \\r\\n\\tfor i in range (1, n + 1) :\\r\\n    if ((i * k == 2)] and (\"+j*k== \"+\") else -\"-\", j)):\\r\\n      musq.append((mu, arr[0]))\\r\\n  returnsmath', 'def re_arrange(testlist):\\r\\n  temp = [ele for sub in test list]\\r\\n  res = tuple()\\r\\n    while (temp > 0) :\\r\\n      if len((res)) < 2:\\r\\n        swapped.append(_key, arr[0])\\r\\n           else:\\\\\\r\\n          None\\r\\n      strcpy([stra], tmp)))\\r', \"def count_common(str1):\\r\\n  ch=sorted([x for x in str2 if not y.isspace()])[:-len('a')] \\r\\n\\tcount = 0\\r\\n  while (not z) :  \\r\\n    n, temp += 1, -sys._maxsize    \\r\\n      intn // 2 == i:\\r\\n        result |= c\\r\\n           break\\r\", 'def find_three(l1, l2, r3):\\r\\n    result = [] \\r\\n     if (len((r)>= 2 * mcl + 1 ) and arr[i] < ((n - 3*mCL+1)) % b == 0 orarr[$-4*(gcd)+b)]!= (\\'none\\', [\\'a\\',\\'c\\'] for a in range(_.min(), _.max()))):\\r\\n            return (\"No\")                                                                                                      else :\\r\\n               result += [efor e within ]  \\r\\n        ', \"def subject_marks(subjects):\\r\\n#setof__members = [('English', 88), ('Science', 90) for a, b in scheduling] \\r\\n\", \"def heap_sort(my_list):\\r\\n    h = []\\r\\n    while len()!= 0:\\r\\n        for i in range(_.maxsize, key=lambda x :x[0]) and remove (your_ list[-1] from the stack)[:-2], -sys._version messglethct=[len([i]))for jin enumerate(), arr[$j]] \\r\\n            if myList [k].count > 1 or y >= _numerities]:\\r\\n                theirscales['heapify'].append((v), a )  \", 'def count_tuple(tup):\\r\\n  res = sum([1 for x in tup if isinstance (x, tuple)) \\r\\n   return str((res)), 2)]', 'def any_element(list1, list2):\\r\\n    result = all((x in  returnresult) for x in l3 if not sdict.isspace()) \\r\\n    else -1\")    \\r\\n   return None', 'import heapq\\r\\ndef combine_sortedlist(nums1, nums2):\\r\\n  result = [heapq.merge(*map((hu\", ab) for a h u in zip(_,\\\\ x), i n z))] \\r\\n  return list()', \"def separate_numbers(text):\\r\\n  return (re.findall('[0-9][^a]*', text))\", 'def tuple_set(testtup):\\r\\n  res = set([tuple() for ele in testT up]) \\r\\n  return (res)', 'import collections\\r\\ndef find_common(testlist, text): \\r\\n  res = dict()    for key in sorted({ele: val}) if test.isalpha(): \\r\\n      result[key] += 1\\r\\n  return (res)', 'def len_Of_Smallest(str): \\r\\n    max=len([x for x in str if not n % word])\\r\\n        return int((max+1) / 2)) ', 'def get_tuple(tup,x):\\r\\n  item = tup[0] \\r\\n  return (item)', 'def sort_tuple(testlist):\\r\\n  res = [str((int)(ele) for ele in test list))] \\r\\n\\treturn (res, key=lambda x:x[1])[:-2], reverse=(True/False).replace(\\'...\\',\\'a\\', \\'\\'.join([idx))) if len() == 0]:\\r\\n    return \"\"\"\"', 'def chinese_zodiac(N): \\r\\n\\tif ( N >= 10 and K > 15) :\\r\\n\\t\\t\\treturn (\"Invalid Input\") \\r\\n\\t\\t\\t\\texit()  \\r\\n        if ((January + 1900 - East), 2*10+1)*chinese zODIAC(\"No Side\"); else:\\r\\n            return \"-\"', \"def max_of_similar(testlist1, test2):\\r\\n  res = tuple((sorted([x for x in map (set__addif, sub )),)) \\r\\n   return ('No match!')\", 'def ncr_modp(n, r, p): \\r\\n    C = [0 for i in range (r+1)] * R[i]  \\r\\n    P=[min()for jinrange((int)(math.sqrt) + 1)*pow(\"\", s)) % modP]; ', \"def find_Minimun(arr,n): \\r\\n    if (len(_set) < 2 * n ):\\r\\n        return -1;  \\r\\n    res = 0;      \\r\\n    for i in range(-2*i+ 1),0,-1 :     \\r\\n          sub[ord('a')] += arr[:idx];    \\r\\n         temp.add((temp + a)) % len([data]))); \\r\\n            buck -= 1(); \\r\\n                count=count*(sub [~#@][::]) // 6\", 'def profit_amount(actual_cost,saleborr): \\r\\n  if (total_price > actual_fee) :\\r\\n    amount = total - fee1\\r\\n   return True\\r\\n else:\\r\\n     res = False\\r\\n      for i in range(_TOTAL/2.0), 0,-1]:\\r\\n        nctx=10**i;\\r\\n         while((n ct x * y <= r)) and lenght>0);\\r\\n                currres += 1\\r\\n           if(\"none\") or (\"negs\" not within the', 'import math \\r\\ndef get_sum(n):    \\r\\n\\tif (len([i for i in range((int)(math.sqrt())) + 1) /2, n)]  \\r\\n\\treturn (\"Valid\") ', \"import re\\r\\ndef split_upperstring(text): \\r\\n  return (re.findall('[A-Z][^a -z]*', text))\", 'import math \\r\\ndef get_Pos(n):   \\r\\n  return (int)(math.log2((1 << n) - 1)) + 2 * pow(*pow, 0));  ', 'def roman_numeral(x):\\r\\n  num = str((int)(y) for y in x)) \\r\\n   return int(\"\".join([str(-n)+1])', 'def average_list(nums):\\r\\n    return [sum (x) / len([i for i in nums if isinstance(_, int))]', 'def tiling_problem(num1, num2): \\r\\n\\tif (Num 1!= Num 2) or (\"Number must be bigger than 0\") :\\r\\n\\t\\t\\treturn False    if ((No solution for this module in range(-3)] + [This file\\'s name]).count(\"0\")):\\r\\n\\t\\t\\t\\tprimes[this].append((LateisticMapping(), function(){   return True})    \\r\\n\\telse:\"\".join([\"\"], nums[$.toString()})))[:])', 'def roman_numeral(n):\\r\\n    num = n.strip()\\r\\n    if not strinicity: \\r\\n        return 0\\r\\n     elif len(\\'A\\')) == 1 or arr[0] in \"0123456789\" :  \\r\\n          raise ValueError else:$       lambda x, y: int(\"\".join([x%2],y))); ', 'def sum_evennumbers(n): \\r\\n    terms = ( n + 1)//2\\r\\n   sum1,terms 2=0;   for i in range((r+l)+1)*pow(\\' \\',i);    \\r\\n        if ((v% 10 == 0 or v % 11!= 9)):                                                                Images            return (\"Invalid\") ', 'def discriminant_value(a,b):\\r\\n  c=0.5 * a + b*c \\r\\n   return (dct)', 'def word_len(s): \\r\\n    s = set()  \\r\\n    for w in st:    \\r\\n        if len([w] == 1) :     \\r\\n            return True;      \\r\\n          else :\\r\\n                res=False;\"\\r\\n        for iin range (2,n+1 ):    \\r\\n                    if ((i % 2!= 0)) and \\\\\\r\\n          ((res + a)/b\\')%4!==0),\"A\"):\"\".join(\"\");\": \\r\\n\\t\\t\\treturn False', \"def snake_to_camel(word):\\r\\n        import re \\r\\n            return ''.join([x for x in word if not any[phrase]])\", \"def remove_tuple(list1):\\r\\n  tuple.extend([x for x in list2 if not X] ) \\r\\n  return (str()).replace('...', '')\", 'def accept_vowels(str1):\\r\\n\\t vow = \"\"; \\r\\n    for char in str2:  \\r\\n        ifchar == \"aeiouAEIOU\":                                                                Would receive VOW!=false;\" or rn >= 10 :    \\r\\n            return False      \\r\\n    else:\\\\\\r\\n         return True        ', 'def max_val(A,B):\\r\\n    x = MAX((INT)(MAX) - 1)) // B; \\r\\n    return (x); ', \"def join_tuples(testlist):\\r\\n  res =''.join([idx for idx in testset if not ele.isspace()]) \\r\\n  return (res)\", 'def minimum(a,b):   \\r\\n if a <= b: \\r\\n      return (min() for x in range((c+1)*max(), c) + 1))  ', 'def max_segment(a, b, c): \\r\\n\\tarr.sort()  \\r\\n\\t\\t\\tmax = 0\\r\\n\\tfor i in range (1, n+ 1) :    \\r\\n\\t\\t\\t\\tif a[i] > x: \\r\\n\\t\\t\\t\\t\\tswapped=False\\r\\n\\t\\t\\t\\t\\t\\telse:\\\\AFFECTEDCWG=[0]*n; AEFENCE[@index][\"add\"] += one*one*(b-c)/2\\r\\n    return maxlen ', 'def concatenate_tuples(testtup1, testTdown2):\\r\\n  res = tuple() \\r\\n  for ele in zip(*temp), tup:\\r\\n    if not isinstance (ele,tuple)) :\\r\\n      break\\r\\n     else:\\\\\\r\\n        temp.append((sub[0], sub[- 1])) \\r\\n                return str(\"\".join([str(_in range(), len($res)))', 'def left_Rotate(string1,d):   \\r\\n  string2 = s + d  \\r\\n  return (String 2-l)', 'def min_path(tri, m-1): \\r\\n\\tfor i in range (m+ 1)] :  \\r\\n\\t\\t\\tif tri[i][0] < triangle[-1]: \\r\\n\\t\\t\\t\\ttrange [idx + 0].append((j*t) for jin enumerate($2)) or\\\\uncontrolled[$id]+=len([row%d])/?$\"\"\")    \\r\\n\\t\\t\\t\\tresult = -min(-three)[sum()]*cntry\\r\\n\\t\\t\\t\\t\\treturn result ']\n"]}],"source":["print(y_pred)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T20:44:18.027272Z","iopub.status.busy":"2024-05-13T20:44:18.026372Z","iopub.status.idle":"2024-05-13T20:44:27.213452Z","shell.execute_reply":"2024-05-13T20:44:27.212628Z","shell.execute_reply.started":"2024-05-13T20:44:18.027221Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting astor\n","  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Installing collected packages: astor\n","Successfully installed astor-0.8.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip install astor"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T21:41:17.464994Z","iopub.status.busy":"2024-05-13T21:41:17.464287Z","iopub.status.idle":"2024-05-13T21:41:17.484323Z","shell.execute_reply":"2024-05-13T21:41:17.483370Z","shell.execute_reply.started":"2024-05-13T21:41:17.464950Z"},"trusted":true},"outputs":[],"source":["import ast\n","import astor\n","import nltk.translate.bleu_score as bleu\n","\n","def token_level_accuracy(y_true, y_pred):\n","    total_tokens = sum(len(code.split()) for code in y_true)\n","    correct_tokens = sum(len(set(true_code.split()) & set(pred_code.split())) for true_code, pred_code in zip(y_true, y_pred))\n","    accuracy = correct_tokens / total_tokens\n","    return accuracy\n","\n","def bleu_score(y_true, y_pred, ngram_order=1):\n","    smoothing_function = bleu.SmoothingFunction()\n","    weights = [1. / ngram_order] * ngram_order  # Equal weights for all n-gram orders\n","    return bleu.corpus_bleu([[true_code.split()] for true_code in y_true], [pred_code.split() for pred_code in y_pred], weights=weights, smoothing_function=smoothing_function.method1)\n","\n","\n","def is_valid_python(code):\n","    try:\n","        ast.parse(code)\n","        return True\n","    except SyntaxError:\n","        return False\n","\n"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T21:45:55.532973Z","iopub.status.busy":"2024-05-13T21:45:55.532210Z","iopub.status.idle":"2024-05-13T21:45:55.538165Z","shell.execute_reply":"2024-05-13T21:45:55.537349Z","shell.execute_reply.started":"2024-05-13T21:45:55.532932Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token-level Accuracy: 0.75\n","BLEU Score: 0.5454545454545454\n"]}],"source":["print(\"Token-level Accuracy:\", token_level_accuracy(y_true, y_pred))\n","print(\"BLEU Score:\", bleu_score(y_true, y_pred))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2108138,"sourceId":3502794,"sourceType":"datasetVersion"}],"dockerImageVersionId":30177,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
